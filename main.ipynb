{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_ae import AgeModel\n",
    "from main_ae import START_AGE, END_AGE, NUM_AGE_GROUPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_AGE_GROUPS = 9\n",
    "VALIDATION_RATE = 0.1\n",
    "num_ages = END_AGE - START_AGE + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f70b5da8530>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(2019)\n",
    "np.random.seed(2019)\n",
    "torch.manual_seed(2019)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIHub dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpt.data import join_face_df\n",
    "from fpt.path import DTFR\n",
    "\n",
    "DATA_CATEGORY = \"aihub_family\"\n",
    "face_df = join_face_df(DTFR, DATA_CATEGORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age\n",
    "age_df = pd.read_csv(\"/home/jupyter/data/dataframe/df_aihub_ages.csv\", index_col=0)\n",
    "face_df = face_df.join(age_df, on=\"target\")\n",
    "\n",
    "# Age group\n",
    "ages = face_df[face_df.category == \"Age\"]\n",
    "age_group_df = ages.key.str.split('_').map(lambda x: x[-1][0]).to_frame(name=\"age_group\")\n",
    "face_df = face_df.join(age_group_df)\n",
    "\n",
    "# Update age\n",
    "face_df.loc[age_group_df.index, \"age\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANGE_TO_MEDIAN = {\n",
    "    \"a\": (1 + 6) / 2,\n",
    "    \"b\": (7 + 12) / 2,\n",
    "    \"c\": (13 + 19) / 2,\n",
    "    \"d\": (20 + 30) / 2,\n",
    "    \"e\": (31 + 45) / 2,\n",
    "    \"f\": (46 + 55) / 2,\n",
    "    \"g\": (56 + 66) / 2,\n",
    "    \"h\": (67 + 80) / 2,\n",
    "    \"above\": 90,\n",
    "}\n",
    "AGE_GROUPS = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"above\"]\n",
    "\n",
    "\n",
    "def age_to_age_groups(age):\n",
    "    if age <= 6:\n",
    "        return \"a\"\n",
    "    if age <= 12:\n",
    "        return \"b\"\n",
    "    if age <= 19:\n",
    "        return \"c\"\n",
    "    if age <= 30:\n",
    "        return \"d\"\n",
    "    if age <= 45:\n",
    "        return \"e\"\n",
    "    if age <= 55:\n",
    "        return \"f\"\n",
    "    if age <= 66:\n",
    "        return \"g\"\n",
    "    if age <= 80:\n",
    "        return \"h\"\n",
    "    return \"above\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age\n",
    "is_age_null = face_df['age'].isnull()\n",
    "range_to_age = face_df.loc[is_age_null, 'age_group'].map(lambda x: RANGE_TO_MEDIAN[x])\n",
    "face_df.loc[is_age_null, 'age'] = range_to_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age group\n",
    "is_age_group_null = face_df['age_group'].isnull()\n",
    "age_groups = face_df.loc[is_age_group_null, 'age'].map(lambda x: age_to_age_groups(int(x)))\n",
    "face_df.loc[is_age_group_null, 'age_group'] = age_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 109468 entries, 391fc9e5-eadd-4896-ab0c-61dffd9ab09c to afb1179b-d620-43c0-bad2-3660d9d73d60\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   key            109468 non-null  object \n",
      " 1   label          109468 non-null  object \n",
      " 2   image          109468 non-null  object \n",
      " 3   category       109468 non-null  object \n",
      " 4   option         109456 non-null  float64\n",
      " 5   data_category  109468 non-null  object \n",
      " 6   folder_name    109468 non-null  object \n",
      " 7   family_id      109468 non-null  object \n",
      " 8   personal_id    109468 non-null  object \n",
      " 9   path           109468 non-null  object \n",
      " 10  target         109468 non-null  object \n",
      " 11  age            109468 non-null  float64\n",
      " 12  age_group      109468 non-null  object \n",
      "dtypes: float64(2), object(11)\n",
      "memory usage: 15.7+ MB\n"
     ]
    }
   ],
   "source": [
    "face_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AgeModel(num_ages, NUM_AGE_GROUPS)  # age_pred, age_group_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import NiaDataset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta_path = \"nia_cropped/train_0.npy\"\n",
    "test_meta_path = \"nia_cropped/test_0.npy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NiaDataset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.RandomApply(\n",
    "            [\n",
    "                torchvision.transforms.RandomAffine(degrees=10, shear=16),\n",
    "                torchvision.transforms.RandomHorizontalFlip(p=1.0),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        torchvision.transforms.Resize((256, 256)),\n",
    "        torchvision.transforms.RandomCrop((224, 224)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = NiaDataset(train_meta_path, transforms_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_gen,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['image', 'age', 'age_class', 'file', 'data_type', 'family_id', 'personal_id'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(train_iter)\n",
    "sample.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image:\ttensor([[[0.8627, 0.8627, 0.8627,  ..., 0.0784, 0.0824, 0.0863],\n",
      "         [0.8627, 0.8667, 0.8667,  ..., 0.0902, 0.0902, 0.0902],\n",
      "         [0.8627, 0.8667, 0.8706,  ..., 0.0980, 0.0941, 0.0863],\n",
      "         ...,\n",
      "         [0.8588, 0.8549, 0.8510,  ..., 0.5373, 0.5294, 0.5216],\n",
      "         [0.8627, 0.8588, 0.8549,  ..., 0.5333, 0.5294, 0.5255],\n",
      "         [0.8549, 0.8510, 0.8510,  ..., 0.5373, 0.5333, 0.5294]],\n",
      "\n",
      "        [[0.8353, 0.8314, 0.8275,  ..., 0.0627, 0.0627, 0.0667],\n",
      "         [0.8353, 0.8314, 0.8314,  ..., 0.0706, 0.0706, 0.0706],\n",
      "         [0.8353, 0.8353, 0.8353,  ..., 0.0784, 0.0745, 0.0667],\n",
      "         ...,\n",
      "         [0.8235, 0.8235, 0.8235,  ..., 0.2980, 0.2902, 0.2824],\n",
      "         [0.8314, 0.8275, 0.8275,  ..., 0.2941, 0.2902, 0.2863],\n",
      "         [0.8235, 0.8196, 0.8235,  ..., 0.2980, 0.2941, 0.2902]],\n",
      "\n",
      "        [[0.8000, 0.8000, 0.8000,  ..., 0.0510, 0.0549, 0.0588],\n",
      "         [0.8039, 0.8039, 0.8039,  ..., 0.0588, 0.0588, 0.0588],\n",
      "         [0.8039, 0.8078, 0.8078,  ..., 0.0667, 0.0627, 0.0549],\n",
      "         ...,\n",
      "         [0.7882, 0.7922, 0.7922,  ..., 0.2275, 0.2196, 0.2118],\n",
      "         [0.7961, 0.7961, 0.7961,  ..., 0.2235, 0.2196, 0.2157],\n",
      "         [0.7882, 0.7882, 0.7922,  ..., 0.2275, 0.2235, 0.2196]]])\n",
      "age:\t76\n",
      "age_class:\t7\n",
      "file:\tF0115_IND_FGM_76_-90_04.JPG\n",
      "data_type:\tkinship\n",
      "family_id:\tF0115\n",
      "personal_id:\tF0115-FGM\n"
     ]
    }
   ],
   "source": [
    "for key in sample.keys():\n",
    "    print(f\"{key}:\\t{sample[key][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uuid\n",
       "391fc9e5-eadd-4896-ab0c-61dffd9ab09c        F0001_AGE_D_18_a1\n",
       "bf42518e-8415-4247-820f-77439018f31d        F0001_AGE_D_18_a2\n",
       "98f0b57c-7a24-423f-b77c-82ed5719c6f4        F0001_AGE_D_18_a3\n",
       "18779095-36e6-4b5d-8181-7a3860c8f012        F0001_AGE_D_18_a4\n",
       "5d7928c2-72f8-412c-8762-835abaea8b00        F0001_AGE_D_18_b1\n",
       "                                                ...          \n",
       "949028f3-9157-4800-8e52-31a5c85a875c    F0900_IND_M_57_-90_02\n",
       "377e54be-0e2f-4a27-8bf3-92b29ea68cad    F0900_IND_M_57_-45_02\n",
       "91e72b0c-2d49-45ae-a208-b7d26e658c14      F0900_IND_M_57_0_02\n",
       "a5fa8816-5d76-41d3-a32a-69c691bc18e9     F0900_IND_M_57_45_02\n",
       "afb1179b-d620-43c0-bad2-3660d9d73d60     F0900_IND_M_57_90_02\n",
       "Name: key, Length: 109468, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_df.key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 1\n",
    "file_name, _ = os.path.splitext(sample['file'][idx])\n",
    "file_name in face_df.key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.Resize((224, 224)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "val_gen = NiaDataset(test_meta_path, transforms)\n",
    "val_loader = DataLoader(\n",
    "    val_gen, batch_size=1, shuffle=False, pin_memory=True, num_workers=0\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA_1 = 0.2\n",
    "LAMBDA_2 = 0.05\n",
    "START_AGE = 0\n",
    "END_AGE = 90\n",
    "learning_rate = 1e-3\n",
    "epoch = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[5, 8, 9], gamma=0.1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mean_variance_loss import MeanVarianceLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion1 = MeanVarianceLoss(LAMBDA_1, LAMBDA_2, START_AGE, END_AGE).cuda\n",
    "criterion2 = torch.nn.CrossEntropyLoss().cuda()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_ae import train_softmax, evaluate_softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_softmax(train_loader, model, criterion2, optimizer, epoch, result_directory):\n",
    "    model.cuda().train()\n",
    "    running_loss = 0.0\n",
    "    running_softmax_loss = 0.0\n",
    "    interval = 1\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        images = sample[\"image\"].cuda()\n",
    "        labels = sample[\"age_class\"].cuda()\n",
    "        _, output = model(images)\n",
    "        loss = criterion2(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.data\n",
    "        if (i + 1) % interval == 0:\n",
    "            print(\"[%d, %5d] loss: %.3f\" % (epoch, i, running_loss / interval))\n",
    "            with open(os.path.join(result_directory, \"log\"), \"a\") as f:\n",
    "                f.write(\"[%d, %5d] loss: %.3f\\n\" % (epoch, i, running_loss / interval))\n",
    "            running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    break\n",
    "    train_softmax(train_loader, model, criterion2, optimizer, epoch, \"result\")\n",
    "    loss_val, mae = evaluate_softmax(val_loader, model, criterion2)\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_val, mae\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from nia_age.main_ae import Embedding, AgeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(Embedding(), AgeClassifier(num_ages, NUM_AGE_GROUPS))\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = sample[\"image\"]\n",
    "images = images.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_age, pred_age_group = model(images)\n",
    "pred_age.shape, pred_age_group.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcface_torch.losses import CombinedMarginLoss\n",
    "from arcface_torch.configs.aihub_r50_onegpu import config as aihub_config\n",
    "from arcface_torch.configs.base import config as cfg\n",
    "\n",
    "cfg.update(aihub_config)\n",
    "cfg.output = \"work_dirs/aihub_r50_onegpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_loss = CombinedMarginLoss(\n",
    "    64,\n",
    "    cfg.margin_list[0],\n",
    "    cfg.margin_list[1],\n",
    "    cfg.margin_list[2],\n",
    "    cfg.interclass_filtering_threshold,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIHubDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet.datasets.AIHubDataset import AIHubDataset\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/jupyter/data/face-image/train_aihub_family'\n",
    "image_size = 112\n",
    "aihub_mean = [0.5444, 0.4335, 0.3800]\n",
    "aihub_std = [0.2672, 0.2295, 0.2156]\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize(size=(image_size, image_size)),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=aihub_mean, std=aihub_std),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.4849e+00,  1.4996e+00,  1.4996e+00,  ...,  1.4849e+00,\n",
       "            1.4996e+00,  1.4849e+00],\n",
       "          [ 1.4996e+00,  1.4996e+00,  1.5143e+00,  ...,  1.4849e+00,\n",
       "            1.4849e+00,  1.4996e+00],\n",
       "          [ 1.5290e+00,  1.5290e+00,  1.5436e+00,  ...,  1.5143e+00,\n",
       "            1.5143e+00,  1.5290e+00],\n",
       "          ...,\n",
       "          [-7.0770e-02, -3.2027e-01, -3.9365e-01,  ..., -7.8992e-01,\n",
       "            4.5759e-01,  5.8967e-01],\n",
       "          [ 1.7289e-02, -1.5883e-01, -7.0770e-02,  ..., -8.1927e-01,\n",
       "            3.1082e-01,  5.7500e-01],\n",
       "          [ 2.6126e-03,  1.7289e-02, -7.0770e-02,  ..., -9.0733e-01,\n",
       "            1.3470e-01,  3.9888e-01]],\n",
       " \n",
       "         [[ 2.2463e+00,  2.2634e+00,  2.2804e+00,  ...,  2.2463e+00,\n",
       "            2.2634e+00,  2.2463e+00],\n",
       "          [ 2.2634e+00,  2.2634e+00,  2.2804e+00,  ...,  2.2463e+00,\n",
       "            2.2463e+00,  2.2634e+00],\n",
       "          [ 2.2804e+00,  2.2975e+00,  2.2975e+00,  ...,  2.2634e+00,\n",
       "            2.2804e+00,  2.2804e+00],\n",
       "          ...,\n",
       "          [ 1.1034e-01, -2.1432e-01, -3.5102e-01,  ..., -3.5102e-01,\n",
       "            1.2894e+00,  1.4773e+00],\n",
       "          [ 7.6167e-02, -1.6306e-01, -1.1179e-01,  ..., -4.7063e-01,\n",
       "            1.0502e+00,  1.4773e+00],\n",
       "          [ 7.8176e-03, -9.2699e-03, -1.6306e-01,  ..., -6.2442e-01,\n",
       "            7.2549e-01,  1.2381e+00]],\n",
       " \n",
       "         [[ 2.5847e+00,  2.6029e+00,  2.5847e+00,  ...,  2.5847e+00,\n",
       "            2.6029e+00,  2.5847e+00],\n",
       "          [ 2.6029e+00,  2.6029e+00,  2.5847e+00,  ...,  2.5847e+00,\n",
       "            2.5847e+00,  2.6029e+00],\n",
       "          [ 2.6392e+00,  2.6574e+00,  2.6392e+00,  ...,  2.6210e+00,\n",
       "            2.6210e+00,  2.6392e+00],\n",
       "          ...,\n",
       "          [-1.6188e-01, -5.4385e-01, -7.2574e-01,  ..., -4.5291e-01,\n",
       "            1.3842e+00,  1.6388e+00],\n",
       "          [-3.2558e-01, -5.9842e-01, -5.6204e-01,  ..., -5.0748e-01,\n",
       "            1.1114e+00,  1.5843e+00],\n",
       "          [-4.8929e-01, -5.2566e-01, -6.5299e-01,  ..., -6.5299e-01,\n",
       "            8.0214e-01,  1.3660e+00]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = ImageFolder(root_dir, transform)\n",
    "next(iter(train_set))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi task Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceAgeDataset(Dataset):\n",
    "    def __init__(self, root_dir, face_df, transform=None):\n",
    "        self.face_dataset = ImageFolder(root=root_dir, transform=transform)\n",
    "        self.face_df = face_df\n",
    "        self.class_to_idx = self.face_dataset.class_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.face_dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, face_label = self.face_dataset[index]\n",
    "        path, _ = self.face_dataset.samples[index]\n",
    "        *_, key = os.path.splitext(path)[0].split(\"/\")\n",
    "        row = self.face_df.loc[key]\n",
    "        age, age_group = row.age, row.age_group\n",
    "        family_id, target = row.family_id, row.target\n",
    "        sample = edict({\n",
    "            \"image\": image,\n",
    "            \"age\": age,\n",
    "            \"age_class\": age_group,\n",
    "            \"file\": path,\n",
    "            \"data_type\": None,\n",
    "            \"family_id\": family_id,\n",
    "            \"personal_id\": self.class_to_idx[target],\n",
    "            \"key\": key,\n",
    "        })\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/jupyter/data/face-image/train_aihub_family\"\n",
    "face_age_dataset = FaceAgeDataset(root_dir, face_df)\n",
    "iterator = iter(face_age_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: <PIL.Image.Image image mode=RGB size=783x783 at 0x7F703C9944D0>\n",
      "age: 75.0\n",
      "age_class: h\n",
      "file: /home/jupyter/data/face-image/train_aihub_family/F0001-GM/d2e77ffa-8278-46a0-9f23-ffad8abcca7d.jpg\n",
      "data_type: None\n",
      "family_id: F0001\n",
      "personal_id: 1\n",
      "key: d2e77ffa-8278-46a0-9f23-ffad8abcca7d\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=80x80>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iterator)\n",
    "[print(f\"{k}: {v}\") for k, v in sample.items()]\n",
    "sample.image.resize((80, 80))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Recognition loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import linear, normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.view(-1, 1)\n",
    "norm_embeddings = normalize(embeddings)\n",
    "norm_weight_activated = normalize(weight)\n",
    "logits = linear(norm_embeddings, norm_weight_activated)\n",
    "logits = logits.clamp(-1, 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
