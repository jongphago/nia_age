{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_ae import AgeModel\n",
    "from main_ae import START_AGE, END_AGE, NUM_AGE_GROUPS, LAMBDA_1, LAMBDA_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_AGE_GROUPS = 9\n",
    "VALIDATION_RATE = 0.1\n",
    "num_ages = END_AGE - START_AGE + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2019)\n",
    "np.random.seed(2019)\n",
    "torch.manual_seed(2019)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIHub dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpt.data import join_face_df\n",
    "from fpt.path import DTFR\n",
    "\n",
    "DATA_CATEGORY = \"aihub_family\"\n",
    "face_df = join_face_df(DTFR, DATA_CATEGORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANGE_TO_MEDIAN = {\n",
    "    \"a\": (1 + 6) / 2,\n",
    "    \"b\": (7 + 12) / 2,\n",
    "    \"c\": (13 + 19) / 2,\n",
    "    \"d\": (20 + 30) / 2,\n",
    "    \"e\": (31 + 45) / 2,\n",
    "    \"f\": (46 + 55) / 2,\n",
    "    \"g\": (56 + 66) / 2,\n",
    "    \"h\": (67 + 80) / 2,\n",
    "    \"above\": 90,\n",
    "}\n",
    "AGE_GROUPS = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"above\"]\n",
    "\n",
    "\n",
    "def age_to_age_groups(age):\n",
    "    if age <= 6:\n",
    "        return \"a\"\n",
    "    if age <= 12:\n",
    "        return \"b\"\n",
    "    if age <= 19:\n",
    "        return \"c\"\n",
    "    if age <= 30:\n",
    "        return \"d\"\n",
    "    if age <= 45:\n",
    "        return \"e\"\n",
    "    if age <= 55:\n",
    "        return \"f\"\n",
    "    if age <= 66:\n",
    "        return \"g\"\n",
    "    if age <= 80:\n",
    "        return \"h\"\n",
    "    return \"above\"\n",
    "\n",
    "GROUP_TO_INDEX = {group: index for index, group in enumerate(AGE_GROUPS)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIA Age Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AgeModel(num_ages, NUM_AGE_GROUPS)  # age_pred, age_group_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import NiaDataset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta_path = \"nia_cropped/train_0.npy\"\n",
    "test_meta_path = \"nia_cropped/test_0.npy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NiaDataset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.RandomApply(\n",
    "            [\n",
    "                torchvision.transforms.RandomAffine(degrees=10, shear=16),\n",
    "                torchvision.transforms.RandomHorizontalFlip(p=1.0),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        torchvision.transforms.Resize((256, 256)),\n",
    "        torchvision.transforms.RandomCrop((224, 224)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = NiaDataset(train_meta_path, transforms_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_gen,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(train_iter)\n",
    "sample.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sample.keys():\n",
    "    print(f\"{key}:\\t{sample[key][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_df.key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "file_name, _ = os.path.splitext(sample['file'][idx])\n",
    "file_name in face_df.key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.Resize((224, 224)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "val_gen = NiaDataset(test_meta_path, transforms)\n",
    "val_loader = DataLoader(\n",
    "    val_gen, batch_size=1, shuffle=False, pin_memory=True, num_workers=0\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA_1 = 0.2\n",
    "LAMBDA_2 = 0.05\n",
    "START_AGE = 0\n",
    "END_AGE = 90\n",
    "learning_rate = 1e-3\n",
    "epoch = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[5, 8, 9], gamma=0.1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mean_variance_loss import MeanVarianceLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion1 = MeanVarianceLoss(LAMBDA_1, LAMBDA_2, START_AGE, END_AGE).cuda\n",
    "criterion2 = torch.nn.CrossEntropyLoss().cuda()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_ae import train_softmax, evaluate_softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_softmax(train_loader, model, criterion2, optimizer, epoch, result_directory):\n",
    "    model.cuda().train()\n",
    "    running_loss = 0.0\n",
    "    running_softmax_loss = 0.0\n",
    "    interval = 1\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        images = sample[\"image\"].cuda()\n",
    "        labels = sample[\"age_class\"].cuda()\n",
    "        _, output = model(images)\n",
    "        loss = criterion2(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.data\n",
    "        if (i + 1) % interval == 0:\n",
    "            print(\"[%d, %5d] loss: %.3f\" % (epoch, i, running_loss / interval))\n",
    "            with open(os.path.join(result_directory, \"log\"), \"a\") as f:\n",
    "                f.write(\"[%d, %5d] loss: %.3f\\n\" % (epoch, i, running_loss / interval))\n",
    "            running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    break\n",
    "    train_softmax(train_loader, model, criterion2, optimizer, epoch, \"result\")\n",
    "    loss_val, mae = evaluate_softmax(val_loader, model, criterion2)\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_val, mae\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-task Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from nia_age.main_ae import Embedding, AgeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(Embedding(), AgeClassifier(num_ages, NUM_AGE_GROUPS))\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = sample[\"image\"]\n",
    "images = images.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_age, pred_age_group = model(images)\n",
    "pred_age.shape, pred_age_group.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcface_torch.losses import CombinedMarginLoss\n",
    "from arcface_torch.configs.aihub_r50_onegpu import config as aihub_config\n",
    "from arcface_torch.configs.base import config as cfg\n",
    "\n",
    "cfg.update(aihub_config)\n",
    "cfg.output = \"work_dirs/aihub_r50_onegpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_loss = CombinedMarginLoss(\n",
    "    64,\n",
    "    cfg.margin_list[0],\n",
    "    cfg.margin_list[1],\n",
    "    cfg.margin_list[2],\n",
    "    cfg.interclass_filtering_threshold,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIHubDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet.datasets.AIHubDataset import AIHubDataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/jupyter/data/face-image/train_aihub_family'\n",
    "image_size = 112\n",
    "aihub_mean = [0.5444, 0.4335, 0.3800]\n",
    "aihub_std = [0.2672, 0.2295, 0.2156]\n",
    "face_age_transform_train = transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize(size=(image_size, image_size)),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=aihub_mean, std=aihub_std),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ImageFolder(root_dir, face_age_transform_train)\n",
    "next(iter(train_set))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi task Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/jupyter/data/face-image/train_aihub_family'\n",
    "image_size = 112\n",
    "aihub_mean = [0.5444, 0.4335, 0.3800]\n",
    "aihub_std = [0.2672, 0.2295, 0.2156]\n",
    "face_age_transform_train = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize(size=(image_size, image_size)),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=aihub_mean, std=aihub_std),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceAgeDataset(Dataset):\n",
    "    def __init__(self, root_dir, face_df, transform):\n",
    "        self.face_dataset = ImageFolder(root=root_dir, transform=transform)\n",
    "        self.face_df = face_df\n",
    "        self.class_to_idx = self.face_dataset.class_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.face_dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, face_label = self.face_dataset[index]\n",
    "        path, _ = self.face_dataset.samples[index]\n",
    "        *_, key = os.path.splitext(path)[0].split(\"/\")\n",
    "        row = face_df.loc[key]\n",
    "        sample = edict({\n",
    "            \"image\": image,\n",
    "            \"age\": row.age,\n",
    "            \"age_class\": GROUP_TO_INDEX[row.age_group],\n",
    "            \"file\": path,\n",
    "            \"data_type\": row.category,\n",
    "            \"family_id\": row.family_id,\n",
    "            \"personal_id\": row.target,\n",
    "            \"face_label\": face_label,\n",
    "            \"key\": key,\n",
    "        })\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/jupyter/data/face-image/train_aihub_family\"\n",
    "face_age_dataset = FaceAgeDataset(root_dir, face_df, face_age_transform_train)\n",
    "iterator = iter(face_age_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iterator)\n",
    "[print(f\"{k}: {v}\") for k, v in sample.items()]\n",
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "\n",
    "def custom_collate(batch):\n",
    "    data = {\n",
    "        key: default_collate([d[key] for d in batch])\n",
    "        for key in batch[0]\n",
    "        if key != \"age\"\n",
    "    }\n",
    "    age = torch.tensor(\n",
    "        [d[\"age\"] for d in batch], dtype=torch.float32\n",
    "    )  # 'age' 필드를 텐서로 변환합니다.\n",
    "    data[\"age\"] = age\n",
    "    return data\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "face_age_loader = DataLoader(\n",
    "    dataset=face_age_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "train_iter = iter(face_age_loader)\n",
    "sample = next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample.family_id)\n",
    "print(sample.age_class)\n",
    "print(sample.personal_id)\n",
    "print(sample.face_label)\n",
    "sample.image.shape, sample.age"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nia_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_ae import AgeModel, Embedding\n",
    "from main_ae import END_AGE, START_AGE, NUM_AGE_GROUPS\n",
    "NUM_AGES = END_AGE - START_AGE + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AgeModel(NUM_AGES, NUM_AGE_GROUPS)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = sample.image.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_pred, age_group_pred = model(images)\n",
    "age_pred.shape, age_group_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Embedding()\n",
    "embedding = embedding.cuda()\n",
    "embedding = embedding.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nia_embedding_result = embedding(images)\n",
    "nia_embedding_result.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ArcFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcface_torch.backbones import get_model\n",
    "from arcface_torch.configs.aihub_r50_onegpu import config as aihub_config\n",
    "from arcface_torch.configs.base import config as cfg\n",
    "\n",
    "cfg.update(aihub_config)\n",
    "cfg.output = \"work_dirs/aihub_r50_onegpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = get_model(\n",
    "    cfg.network,\n",
    "    dropout=0.0,\n",
    "    fp16=False,\n",
    "    num_features=512,\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = torch.load(\n",
    "    f\"/home/jupyter/family-photo-tree/utils/model/arcface/{cfg.network}/backbone.pth\"\n",
    ")\n",
    "backbone.load_state_dict(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = backbone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface_result = backbone(images)\n",
    "arcface_result.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age Classifier with ArcFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_ae import AgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_classifier = AgeClassifier(NUM_AGES, NUM_AGE_GROUPS).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_age_with_arcface, pred_age_group_with_arcface = age_classifier(arcface_result)\n",
    "pred_age_with_arcface.shape, pred_age_group_with_arcface.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy_loss_nia = torch.nn.CrossEntropyLoss().cuda()\n",
    "age_loss = cross_entropy_loss_nia(age_pred, sample.age.cuda())\n",
    "age_group_loss = cross_entropy_loss_nia(age_group_pred, sample.age_class.cuda()) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean-Variance Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mean_variance_loss import MeanVarianceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_variance_loss = MeanVarianceLoss(LAMBDA_1, LAMBDA_2, START_AGE, END_AGE).cuda()\n",
    "mean_loss, variance_loss = mean_variance_loss(age_pred, sample.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_nia = mean_loss + variance_loss + age_loss + 10 * age_group_loss\n",
    "total_loss_nia"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CombinedMarginLoss | ArcFace | CosFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcface_torch.losses import CombinedMarginLoss, ArcFace, CosFace\n",
    "from torch.nn.functional import normalize, linear\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "num_classes = len(face_age_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_loss = CombinedMarginLoss(\n",
    "    64,\n",
    "    cfg.margin_list[0],\n",
    "    cfg.margin_list[1],\n",
    "    cfg.margin_list[2],\n",
    "    cfg.interclass_filtering_threshold,\n",
    ")\n",
    "arc_face_loss = ArcFace()\n",
    "cos_face_loss = CosFace()\n",
    "cross_entropy_loss_arcface = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "labels = sample.face_label.cuda()\n",
    "labels.squeeze_()\n",
    "labels = labels.long()\n",
    "labels = labels.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings\n",
    "norm_embeddings = normalize(arcface_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight\n",
    "weight = torch.nn.Parameter(torch.normal(0, 0.01, (num_classes, 512))).cuda()\n",
    "norm_weight_activated = normalize(weight)\n",
    "norm_weight_activated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits\n",
    "logits = linear(norm_embeddings, norm_weight_activated)\n",
    "logits = logits.clamp(-1, 1)\n",
    "# softmax = margin_loss(logits, labels)\n",
    "# softmax = arc_face_loss(logits, labels)\n",
    "softmax = cos_face_loss(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "loss_arcface = cross_entropy_loss_arcface(softmax, labels.flatten())\n",
    "loss_arcface"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from arcface_torch.lr_scheduler import PolyScheduler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nia_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_nia = Adam(model.parameters(), lr=0.001)\n",
    "scheduler_nia = StepLR(optimizer_nia, 5)\n",
    "optimizer_nia.zero_grad()\n",
    "total_loss_nia.backward()\n",
    "optimizer_nia.step()\n",
    "scheduler_nia.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ArcFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum = 0.9  #\n",
    "weight_decay = 5e-4  #\n",
    "lr = 0.02\n",
    "\n",
    "opt = torch.optim.SGD(\n",
    "    params=[\n",
    "        {\"params\": backbone.parameters()},\n",
    "        {\"params\": margin_loss.parameters()},\n",
    "    ],\n",
    "    lr=lr,\n",
    "    momentum=momentum,\n",
    "    weight_decay=weight_decay,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 2\n",
    "world_size = 1\n",
    "cfg.total_batch_size = cfg.batch_size * world_size\n",
    "cfg.warmup_step = cfg.num_image // cfg.total_batch_size * cfg.warmup_epoch\n",
    "cfg.total_step = cfg.num_image // cfg.total_batch_size * num_epoch\n",
    "\n",
    "lr_scheduler = PolyScheduler(\n",
    "    optimizer=opt,\n",
    "    base_lr=lr,\n",
    "    max_steps=cfg.total_step,\n",
    "    warmup_steps=cfg.warmup_step,\n",
    "    last_epoch=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.zero_grad()\n",
    "loss_arcface.backward()\n",
    "opt.step()\n",
    "lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "# 시각화\n",
    "dot = make_dot(total_loss_nia, params=dict(model.named_parameters()))\n",
    "dot.format = \"pdf\"  # 'png'로 형식 변경\n",
    "dot.render(\"graph\")  # 'graph.png' 파일로 저장"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NIA Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_loss = 0.\n",
    "interval = 10\n",
    "for index, sample in enumerate(face_age_loader):\n",
    "    images = sample.image.cuda()\n",
    "    labels = sample.age.cuda()\n",
    "    age_pred, age_group_red = model(images)\n",
    "    age_loss = cross_entropy_loss_nia(age_pred, labels)\n",
    "    optimizer_nia.zero_grad()\n",
    "    age_loss.backward()\n",
    "    optimizer_nia.step()\n",
    "    running_loss += age_loss.data\n",
    "    if (index + 1) % interval == 0:\n",
    "        print(f\"loss: {running_loss/interval:.3f}\")\n",
    "        running_loss = 0.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
