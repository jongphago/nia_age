{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_ae import AgeModel\n",
    "from main_ae import START_AGE, END_AGE, NUM_AGE_GROUPS, LAMBDA_1, LAMBDA_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_AGE_GROUPS = 9\n",
    "VALIDATION_RATE = 0.1\n",
    "num_ages = END_AGE - START_AGE + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2019)\n",
    "np.random.seed(2019)\n",
    "torch.manual_seed(2019)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIHub dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpt.data import join_face_df\n",
    "from fpt.path import DTFR\n",
    "\n",
    "DATA_CATEGORY = \"aihub_family\"\n",
    "face_df = join_face_df(DTFR, DATA_CATEGORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age\n",
    "age_df = pd.read_csv(\"/home/jupyter/data/dataframe/df_aihub_ages.csv\", index_col=0)\n",
    "face_df = face_df.join(age_df, on=\"target\")\n",
    "\n",
    "# Age group\n",
    "ages = face_df[face_df.category == \"Age\"]\n",
    "age_group_df = ages.key.str.split('_').map(lambda x: x[-1][0]).to_frame(name=\"age_group\")\n",
    "face_df = face_df.join(age_group_df)\n",
    "\n",
    "# Update age\n",
    "face_df.loc[age_group_df.index, \"age\"] = None\n",
    "\n",
    "face_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANGE_TO_MEDIAN = {\n",
    "    \"a\": (1 + 6) / 2,\n",
    "    \"b\": (7 + 12) / 2,\n",
    "    \"c\": (13 + 19) / 2,\n",
    "    \"d\": (20 + 30) / 2,\n",
    "    \"e\": (31 + 45) / 2,\n",
    "    \"f\": (46 + 55) / 2,\n",
    "    \"g\": (56 + 66) / 2,\n",
    "    \"h\": (67 + 80) / 2,\n",
    "    \"above\": 90,\n",
    "}\n",
    "AGE_GROUPS = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"above\"]\n",
    "\n",
    "\n",
    "def age_to_age_groups(age):\n",
    "    if age <= 6:\n",
    "        return \"a\"\n",
    "    if age <= 12:\n",
    "        return \"b\"\n",
    "    if age <= 19:\n",
    "        return \"c\"\n",
    "    if age <= 30:\n",
    "        return \"d\"\n",
    "    if age <= 45:\n",
    "        return \"e\"\n",
    "    if age <= 55:\n",
    "        return \"f\"\n",
    "    if age <= 66:\n",
    "        return \"g\"\n",
    "    if age <= 80:\n",
    "        return \"h\"\n",
    "    return \"above\"\n",
    "\n",
    "GROUP_TO_INDEX = {group: index for index, group in enumerate(AGE_GROUPS)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age\n",
    "is_age_null = face_df['age'].isnull()\n",
    "range_to_age = face_df.loc[is_age_null, 'age_group'].map(lambda x: RANGE_TO_MEDIAN[x])\n",
    "face_df.loc[is_age_null, 'age'] = range_to_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age group\n",
    "is_age_group_null = face_df['age_group'].isnull()\n",
    "age_groups = face_df.loc[is_age_group_null, 'age'].map(lambda x: age_to_age_groups(int(x)))\n",
    "face_df.loc[is_age_group_null, 'age_group'] = age_groups\n",
    "face_df.age = face_df.age.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AgeModel(num_ages, NUM_AGE_GROUPS)  # age_pred, age_group_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import NiaDataset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta_path = \"nia_cropped/train_0.npy\"\n",
    "test_meta_path = \"nia_cropped/test_0.npy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NiaDataset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.RandomApply(\n",
    "            [\n",
    "                torchvision.transforms.RandomAffine(degrees=10, shear=16),\n",
    "                torchvision.transforms.RandomHorizontalFlip(p=1.0),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        torchvision.transforms.Resize((256, 256)),\n",
    "        torchvision.transforms.RandomCrop((224, 224)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = NiaDataset(train_meta_path, transforms_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_gen,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(train_iter)\n",
    "sample.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sample.keys():\n",
    "    print(f\"{key}:\\t{sample[key][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_df.key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "file_name, _ = os.path.splitext(sample['file'][idx])\n",
    "file_name in face_df.key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.Resize((224, 224)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "val_gen = NiaDataset(test_meta_path, transforms)\n",
    "val_loader = DataLoader(\n",
    "    val_gen, batch_size=1, shuffle=False, pin_memory=True, num_workers=0\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA_1 = 0.2\n",
    "LAMBDA_2 = 0.05\n",
    "START_AGE = 0\n",
    "END_AGE = 90\n",
    "learning_rate = 1e-3\n",
    "epoch = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[5, 8, 9], gamma=0.1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mean_variance_loss import MeanVarianceLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion1 = MeanVarianceLoss(LAMBDA_1, LAMBDA_2, START_AGE, END_AGE).cuda\n",
    "criterion2 = torch.nn.CrossEntropyLoss().cuda()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_ae import train_softmax, evaluate_softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_softmax(train_loader, model, criterion2, optimizer, epoch, result_directory):\n",
    "    model.cuda().train()\n",
    "    running_loss = 0.0\n",
    "    running_softmax_loss = 0.0\n",
    "    interval = 1\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        images = sample[\"image\"].cuda()\n",
    "        labels = sample[\"age_class\"].cuda()\n",
    "        _, output = model(images)\n",
    "        loss = criterion2(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.data\n",
    "        if (i + 1) % interval == 0:\n",
    "            print(\"[%d, %5d] loss: %.3f\" % (epoch, i, running_loss / interval))\n",
    "            with open(os.path.join(result_directory, \"log\"), \"a\") as f:\n",
    "                f.write(\"[%d, %5d] loss: %.3f\\n\" % (epoch, i, running_loss / interval))\n",
    "            running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    break\n",
    "    train_softmax(train_loader, model, criterion2, optimizer, epoch, \"result\")\n",
    "    loss_val, mae = evaluate_softmax(val_loader, model, criterion2)\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_val, mae\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from nia_age.main_ae import Embedding, AgeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(Embedding(), AgeClassifier(num_ages, NUM_AGE_GROUPS))\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = sample[\"image\"]\n",
    "images = images.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_age, pred_age_group = model(images)\n",
    "pred_age.shape, pred_age_group.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcface_torch.losses import CombinedMarginLoss\n",
    "from arcface_torch.configs.aihub_r50_onegpu import config as aihub_config\n",
    "from arcface_torch.configs.base import config as cfg\n",
    "\n",
    "cfg.update(aihub_config)\n",
    "cfg.output = \"work_dirs/aihub_r50_onegpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_loss = CombinedMarginLoss(\n",
    "    64,\n",
    "    cfg.margin_list[0],\n",
    "    cfg.margin_list[1],\n",
    "    cfg.margin_list[2],\n",
    "    cfg.interclass_filtering_threshold,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIHubDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet.datasets.AIHubDataset import AIHubDataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/jupyter/data/face-image/train_aihub_family'\n",
    "image_size = 112\n",
    "aihub_mean = [0.5444, 0.4335, 0.3800]\n",
    "aihub_std = [0.2672, 0.2295, 0.2156]\n",
    "face_age_transform_train = transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize(size=(image_size, image_size)),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=aihub_mean, std=aihub_std),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ImageFolder(root_dir, face_age_transform_train)\n",
    "next(iter(train_set))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi task Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/jupyter/data/face-image/train_aihub_family'\n",
    "image_size = 112\n",
    "aihub_mean = [0.5444, 0.4335, 0.3800]\n",
    "aihub_std = [0.2672, 0.2295, 0.2156]\n",
    "face_age_transform_train = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize(size=(image_size, image_size)),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=aihub_mean, std=aihub_std),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceAgeDataset(Dataset):\n",
    "    def __init__(self, root_dir, face_df, transform):\n",
    "        self.face_dataset = ImageFolder(root=root_dir, transform=transform)\n",
    "        self.face_df = face_df\n",
    "        self.class_to_idx = self.face_dataset.class_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.face_dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, face_label = self.face_dataset[index]\n",
    "        path, _ = self.face_dataset.samples[index]\n",
    "        *_, key = os.path.splitext(path)[0].split(\"/\")\n",
    "        row = face_df.loc[key]\n",
    "        sample = edict({\n",
    "            \"image\": image,\n",
    "            \"age\": row.age,\n",
    "            \"age_class\": GROUP_TO_INDEX[row.age_group],\n",
    "            \"file\": path,\n",
    "            \"data_type\": row.category,\n",
    "            \"family_id\": row.family_id,\n",
    "            \"personal_id\": row.target,\n",
    "            \"face_label\": face_label,\n",
    "            \"key\": key,\n",
    "        })\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/jupyter/data/face-image/train_aihub_family\"\n",
    "face_age_dataset = FaceAgeDataset(root_dir, face_df, face_age_transform_train)\n",
    "iterator = iter(face_age_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iterator)\n",
    "[print(f\"{k}: {v}\") for k, v in sample.items()]\n",
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "\n",
    "def custom_collate(batch):\n",
    "    data = {\n",
    "        key: default_collate([d[key] for d in batch])\n",
    "        for key in batch[0]\n",
    "        if key != \"age\"\n",
    "    }\n",
    "    age = torch.tensor(\n",
    "        [d[\"age\"] for d in batch], dtype=torch.float32\n",
    "    )  # 'age' 필드를 텐서로 변환합니다.\n",
    "    data[\"age\"] = age\n",
    "    return data\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "face_age_loader = DataLoader(\n",
    "    dataset=face_age_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "train_iter = iter(face_age_loader)\n",
    "sample = next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample.family_id)\n",
    "print(sample.age_class)\n",
    "print(sample.personal_id)\n",
    "print(sample.face_label)\n",
    "sample.image.shape, sample.age"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nia_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_ae import AgeModel, Embedding\n",
    "from main_ae import END_AGE, START_AGE, NUM_AGE_GROUPS\n",
    "NUM_AGES = END_AGE - START_AGE + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AgeModel(NUM_AGES, NUM_AGE_GROUPS)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = sample.image.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_pred, age_group_pred = model(images)\n",
    "age_pred.shape, age_group_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Embedding()\n",
    "embedding = embedding.cuda()\n",
    "embedding = embedding.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nia_embedding_result = embedding(images)\n",
    "nia_embedding_result.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ArcFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcface_torch.backbones import get_model\n",
    "from arcface_torch.configs.aihub_r50_onegpu import config as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = get_model(\n",
    "    cfg.network,\n",
    "    dropout=0.0,\n",
    "    fp16=False,\n",
    "    num_features=512,\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = torch.load(\n",
    "    f\"/home/jupyter/family-photo-tree/utils/model/arcface/{cfg.network}/backbone.pth\"\n",
    ")\n",
    "backbone.load_state_dict(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = backbone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface_result = backbone(images)\n",
    "arcface_result.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age Classifier with ArcFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_ae import AgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_classifier = AgeClassifier(NUM_AGES, NUM_AGE_GROUPS).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_age_with_arcface, pred_age_group_with_arcface = age_classifier(arcface_result)\n",
    "pred_age_with_arcface.shape, pred_age_group_with_arcface.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion2 = torch.nn.CrossEntropyLoss().cuda()\n",
    "age_loss = criterion2(age_pred, sample.age.cuda())\n",
    "age_group_loss = criterion2(age_group_pred, sample.age_class.cuda()) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean-Variance Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mean_variance_loss import MeanVarianceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion1 = MeanVarianceLoss(LAMBDA_1, LAMBDA_2, START_AGE, END_AGE).cuda()\n",
    "mean_loss, variance_loss = criterion1(age_pred, sample.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = mean_loss + variance_loss + age_loss + 10 * age_group_loss\n",
    "loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CombinedMarginLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcface_torch.losses import ArcFace, CombinedMarginLoss\n",
    "from torch.nn.functional import normalize, linear\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn import NLLLoss  # Negative Log Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_loss = CombinedMarginLoss(\n",
    "    64,\n",
    "    cfg.margin_list[0],\n",
    "    cfg.margin_list[1],\n",
    "    cfg.margin_list[2],\n",
    "    cfg.interclass_filtering_threshold,\n",
    ")\n",
    "dist_cross_entropy = torch.nn.CrossEntropyLoss()\n",
    "criterion = NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "labels = sample.face_label.cuda()\n",
    "labels = labels.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings\n",
    "norm_embeddings = normalize(arcface_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight\n",
    "num_classes = len(face_age_dataset.class_to_idx)\n",
    "weight = torch.nn.Parameter(torch.normal(0, 0.01, (num_classes, 512))).cuda()\n",
    "print(weight.shape)\n",
    "norm_weight_activated = normalize(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits\n",
    "logits = linear(norm_embeddings, norm_weight_activated)\n",
    "logits = logits.clamp(-1, 1)\n",
    "logits = margin_loss(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "criterion3 = CrossEntropyLoss()\n",
    "softmax = margin_loss(logits, labels)\n",
    "loss3 = criterion3(softmax, labels.flatten())\n",
    "loss3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
